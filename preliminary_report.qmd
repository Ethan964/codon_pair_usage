---
title: 'Codon Pairing Usage Model Summary'
author: 'Ethan Long'
toc: true
number-sections: true
highlight-style: pygments
format: 
  pdf: 
    documentclass: article
    number-sections: true
    toc: true
    geometry:
      - top=30mm
      - left=20mm
    html:
      code-fold: true
      html-math-method: katex
---

# Background & Objective

This report summarrizes our first modeling effort aimed at predicting
phosphorylation events based on sequence-level features. The objetive was to 
build a binary classification model that uses variables from the 
'final_filtered_mut_netphos.csv' dataset. The target variable that we are 
trying to predict is 'Answer', a binary outcome where: 

+ 'Yes' = predicted phosphorylation event
+ 'No' = no predicted phosphorylation event

# Feature Definitions & Dataset Observations

We explored several key variables and transformed them to ensure compatability
with machine learning models:

+ Kinase, Mut, WT (Dummy Variables):

These categorical variables were converted into dummy variables. A dummy 
variable is a binary indicator (0, 1) representing the presence or absence of a
particular category. For example, the kinase "PKC" would be represented as a 
column kinase_PKC = 1 if the row involves PKC, 0 otherwise. This allows machine
learning models to handle these categorical inputs effectively. 

+ Position: 

Initially, this feature seemed promising as certain sequence locations may
inherently be more prone to phosphorylation. However, during exploratory 
analysis, we observed that position is highly predictive, bordering 
deterministic. This raised concerns of data leakage, where the model learns to 
to 'memorize' certain 'positions' affecting phosphorylation outcomes, limiting 
the model's ability to learn and pick up trends within the data. Due to this
reasoning 'position' was excluded from final models to ensure the integrity of 
our model.

+ Score: 

We found this continuous variable could alone predict the 'Answer' label with
extremely high accuracy, essentially replicating the label. Including 'Score'
would have led the model to fall in the same trap that including 'pos' creates.
We removed 'Score' to keep the model independent from this metric and ensure
the integrity of the findings of our model. 

# Modeling Approach 


## What Goes In (Inputs)

After preprocessing, each data point or instance represents a case where
either phosphorylation occurs or not. This includes a select set of features
including:

+ **Dummy Variables** indicating the presence of a specific kinase, wild-type,
or mutation

+ Other numerical or structural features that model uses to learn
  + First iteration of models included 'score' or 'pos' 


## What Happens (Model Training)

We trained two types of tree-bsed ensemble models:

+ **Random Forest** which builds numerous decision trees on random sections of
the dataset. The model has each tree learn from a simple 'if then' procedure. 

An example of this could look like: If 'kinase_PKA' and 'Mut_A', then 'Answer' = YES


+ **XGBoost (Extreme Gradient Boosting)** builds trees one at a time, where each
new tree tries to correct the mistakes made by the previous ones. It can be
more useful to use on data that can be harder to classify, but performs better
on structured data.

In both models, SMOTE (Synthetic Minority Oversampling Technique) was applied 
before training to balance the class sizes. This ensures the model isn't 
learning to always predict the majority class ('no' phosphorylation).

## What Comes Out (Results)

Each model outputs two results for each instance:

+ A prediction: either a 'yes' or 'no'

+ A probability score: a number between 0 and 1 indicating the model's confidence
in it's prediction

We then compare these predictions to the true labels of each instance to calculate
metrics like precision, recall, accuracy, and ROC AUC. 

# Evaluation Metrics

We used several standard evaluation metrics:

+ Accuracy: Precentage of total predictions that were correct.

+ Precision: Of predicted 'yes' (phosphorylation) cases, how many were actually
correct? 

+ Recall: Of predicted 'yes' (phosphorylation) cases, how many did we correctly
catch? 

+ F1-Score: A balancxe between precision and recall.

+ ROC AUC (Receiver Operating Ccharacteristic): Measures the model's ability to
distinguish between classes
  + 1.0 - perfect
  + 0.5 - coin flip

Each metrics is reported seperately for:

+ Class 0 = no phosphorylation 
+ Class 1 = phosphorylation occurs

# Results & Model Comparison

## Random Forest (with 'Pos')

| Class | Precision | Recall | F1-Score | 
|-----------|-----------|--------|---------------|
| 0 (no) | 0.85 | 0.81 | 0.83 | 
| 1 (yes) | 0.82 | 0.85 | 0.84 |
| Accuracy | 0.83
| ROC-AUC | 0.91


## Random Forest Without 'Pos'

| Class | Precision | Recall | F1-Score | 
|-----------|-----------|--------|---------------|
| 0 (no) | 0.87 | 0.76 | 0.81 | 
| 1 (yes) | 0.79 | 0.89 | 0.84 |
| Accuracy | 0.83
| ROC-AUC | 0.89

## XGBoost on Oversampled Data

| Class | Precision | Recall | F1-Score | 
|-----------|-----------|--------|---------------|
| 0 (no) | 0.87 | 0.76 | 0.81 | 
| 1 (yes) | 0.79 | 0.89 | 0.83 |
| Accuracy | 0.82
| ROC-AUC | 0.89

# Questions

+ Is the uniform distribution of kinase types an intentional design choice, or 
a result of how the data was selected or filtered?
+ Is there a biological threshold for interpreting 'Score' values? For 
example, does a value above 50% indicate a high confidence in a phosphorylation
event occuring?
+ Why are only 2 wild-types represented,  while all kinase types appear with
roughly equal frequency? 
+ Is Position a critical piece to this project, or can we safely exclude it from
modeling without undermining the project's goals? 
it from modeling? 